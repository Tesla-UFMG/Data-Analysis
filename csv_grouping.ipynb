{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fbb94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b86a377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colunas que vao para o arquivo FULL final\n",
    "columns = [\n",
    "    \"timestamp\",\n",
    "    \"THROTTLE\",\n",
    "    \"BRAKE\",\n",
    "    \"ECU_MODE_ID\",\n",
    "    \"TORQUE_GAIN\",\n",
    "    \"TORQUE_REF_LEFT_MOTOR\",\n",
    "    \"TORQUE_REF_RIGHT_MOTOR\",\n",
    "    \"LEFT_MOTOR_SPEED\",\n",
    "    \"RIGHT_MOTOR_SPEED\",\n",
    "    \"ACCEL_LONGITUDINAL\",\n",
    "    \"STACK_1_CELL_1\",\n",
    "    \"STACK_1_CELL_2\",\n",
    "    \"STACK_1_CELL_3\",\n",
    "    \"STACK_1_CELL_4\",\n",
    "    \"STACK_2_CELL_1\",\n",
    "    \"STACK_2_CELL_2\",\n",
    "    \"STACK_2_CELL_3\",\n",
    "    \"STACK_2_CELL_4\",\n",
    "    \"STACK_3_CELL_1\",\n",
    "    \"STACK_3_CELL_2\",\n",
    "    \"STACK_3_CELL_3\",\n",
    "    \"STACK_3_CELL_4\",\n",
    "    \"STACK_4_CELL_1\",\n",
    "    \"STACK_4_CELL_2\",\n",
    "    \"STACK_4_CELL_3\",\n",
    "    \"STACK_4_CELL_4\",\n",
    "    \"STACK_5_CELL_1\",\n",
    "    \"STACK_5_CELL_2\",\n",
    "    \"STACK_5_CELL_3\",\n",
    "    \"STACK_5_CELL_4\",\n",
    "    \"STACK_6_CELL_1\",\n",
    "    \"STACK_6_CELL_2\",\n",
    "    \"STACK_6_CELL_3\",\n",
    "    \"STACK_6_CELL_4\",\n",
    "    \"MAX_VOLTAGE\",\n",
    "    \"MIN_VOLTAGE\",\n",
    "    \"TOTAL_VOLTAGE\",\n",
    "    \"SHUNT_CURRENT\",\n",
    "    \"BMS_MODE_ID\",\n",
    "    \"BMS_ERROR_ID\",\n",
    "    \"AIR_P\",\n",
    "    \"AIR_N\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92828238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamps de interesse\n",
    "# nome: (inicio, fim)\n",
    "interest_timestamps = {\n",
    "    # miguelito\n",
    "    \"aceleracao1_miguelito\": (\"2025-12-08 15:38:00\", \"2025-12-08 15:38:30\"), # aceleração bem leve, estranho\n",
    "    \"autocross1_miguelito\":  (\"2025-12-08 15:28:25\", \"2025-12-08 15:29:00\"), # incompleto, shunt ruim\n",
    "    \"autocross2_miguelito\":  (\"2025-12-08 15:39:20\", \"2025-12-08 15:40:00\"), # OK\n",
    "    \"autocross3_miguelito\":  (\"2025-12-08 15:43:30\", \"2025-12-08 15:45:30\"), # OK\n",
    "    \"aceleracao2_miguelito\": (\"2025-12-08 15:47:40\", \"2025-12-08 15:48:00\"), # com falha de subtensão\n",
    "    \"autocross4_miguelito\": (\"2025-12-08 15:49:00\", \"2025-12-08 15:50:00\"), # OK\n",
    "    \"aceleracao3_miguelito\": (\"2025-12-08 16:13:15\", \"2025-12-08 16:13:35\"), # bom\n",
    "    \"autocross5_miguelito\": (\"2025-12-08 16:16:00\", \"2025-12-08 16:17:30\"), # OK\n",
    "    \"aceleracao4_miguelito\": (\"2025-12-08 16:21:40\", \"2025-12-08 16:22:15\"), # com falha de subtensão\n",
    "    \"aceleracao5_miguelito\": (\"2025-12-08 16:39:00\", \"2025-12-08 16:39:30\"), # com falha de subtensão\n",
    "\n",
    "    # mike\n",
    "    \"aceleracao1_mike\": (\"2025-12-08 17:01:00\", \"2025-12-08 17:01:20\"), # com falha de subtensão\n",
    "    \"autocross1_mike\": (\"2025-12-08 17:03:00\", \"2025-12-08 17:04:15\"), \n",
    "    \"aceleracao2_mike\": (\"2025-12-08 17:07:20\", \"2025-12-08 17:07:45\"), # com falha de subtensão\n",
    "    \"aceleracao3_mike\": (\"2025-12-08 17:10:40\", \"2025-12-08 17:11:05\"), # 50 km/h, publico\n",
    "    \"autocross2_mike\": (\"2025-12-08 17:21:00\", \"2025-12-08 17:24:30\"), \n",
    "    \"aceleracao4_mike\": (\"2025-12-08 17:26:45\", \"2025-12-08 17:27:00\"), # com falha de subtensão\n",
    "    \"autocross3_mike\": (\"2025-12-08 17:28:15\", \"2025-12-08 17:31:15\"), \n",
    "    \"aceleracao5_mike\": (\"2025-12-08 17:33:45\", \"2025-12-08 17:34:00\"), # com falha de subtensão\n",
    "    \"aceleracao6_mike\": (\"2025-12-08 17:40:50\", \"2025-12-08 17:41:10\"), # com falha de subtensão\n",
    "\n",
    "    # pedro\n",
    "    \"autocross1_pedro\": (\"2025-12-08 18:01:45\", \"2025-12-08 18:04:30\"), # tensoes estranhas nas stacks\n",
    "    \"aceleracao1_pedro\": (\"2025-12-08 18:16:25\", \"2025-12-08 18:16:45\"), # com falha de subtensão\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9df0e896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>THROTTLE</th>\n",
       "      <th>BRAKE</th>\n",
       "      <th>ECU_MODE_ID</th>\n",
       "      <th>TORQUE_GAIN</th>\n",
       "      <th>TORQUE_REF_LEFT_MOTOR</th>\n",
       "      <th>TORQUE_REF_RIGHT_MOTOR</th>\n",
       "      <th>LEFT_MOTOR_SPEED</th>\n",
       "      <th>RIGHT_MOTOR_SPEED</th>\n",
       "      <th>ACCEL_LONGITUDINAL</th>\n",
       "      <th>...</th>\n",
       "      <th>STACK_6_CELL_3</th>\n",
       "      <th>STACK_6_CELL_4</th>\n",
       "      <th>MAX_VOLTAGE</th>\n",
       "      <th>MIN_VOLTAGE</th>\n",
       "      <th>TOTAL_VOLTAGE</th>\n",
       "      <th>SHUNT_CURRENT</th>\n",
       "      <th>BMS_MODE_ID</th>\n",
       "      <th>BMS_ERROR_ID</th>\n",
       "      <th>AIR_P</th>\n",
       "      <th>AIR_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, THROTTLE, BRAKE, ECU_MODE_ID, TORQUE_GAIN, TORQUE_REF_LEFT_MOTOR, TORQUE_REF_RIGHT_MOTOR, LEFT_MOTOR_SPEED, RIGHT_MOTOR_SPEED, ACCEL_LONGITUDINAL, STACK_1_CELL_1, STACK_1_CELL_2, STACK_1_CELL_3, STACK_1_CELL_4, STACK_2_CELL_1, STACK_2_CELL_2, STACK_2_CELL_3, STACK_2_CELL_4, STACK_3_CELL_1, STACK_3_CELL_2, STACK_3_CELL_3, STACK_3_CELL_4, STACK_4_CELL_1, STACK_4_CELL_2, STACK_4_CELL_3, STACK_4_CELL_4, STACK_5_CELL_1, STACK_5_CELL_2, STACK_5_CELL_3, STACK_5_CELL_4, STACK_6_CELL_1, STACK_6_CELL_2, STACK_6_CELL_3, STACK_6_CELL_4, MAX_VOLTAGE, MIN_VOLTAGE, TOTAL_VOLTAGE, SHUNT_CURRENT, BMS_MODE_ID, BMS_ERROR_ID, AIR_P, AIR_N]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 42 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.DataFrame([], columns=columns)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe748cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    \"76_DRIVER_INPUTS.csv\",\n",
    "    \"77_ECU_MODE.csv\",\n",
    "    \"78_TORQUE_REFERENCE.csv\",\n",
    "    \"79_WHEEL_SPEED.csv\",\n",
    "    \"80_MOTOR_SPEED.csv\",\n",
    "    \"85_LEFT_MOTOR_TRACTIVE.csv\",\n",
    "    \"95_RIGHT_MOTOR_TRACTIVE.csv\",\n",
    "    \"259_ACCELEROMETER.csv\",\n",
    "    \"260_GYROSCOPE.csv\",\n",
    "    \"261_ELETROBUILD_TEMPERATURE.csv\",\n",
    "    \"300_STACK_1_VOLTAGE.csv\",\n",
    "    \"301_STACK_2_VOLTAGE.csv\",\n",
    "    \"302_STACK_3_VOLTAGE.csv\",\n",
    "    \"303_STACK_4_VOLTAGE.csv\",\n",
    "    \"304_STACK_5_VOLTAGE.csv\",\n",
    "    \"305_STACK_6_VOLTAGE.csv\",\n",
    "    \"306_ACCUMULADOR_PARAMS.csv\",\n",
    "    \"307_BMS_PARAMS.csv\",\n",
    "]\n",
    "\n",
    "folder_names = [\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste1_0812\",\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste2_0812\",\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste4_0812\",\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste5_0812\",\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste7_longer\",\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste8\",\n",
    "]\n",
    "\n",
    "stacks_list = [\n",
    "    'STACK_1_CELL_1', 'STACK_1_CELL_2', 'STACK_1_CELL_3', 'STACK_1_CELL_4',\n",
    "    'STACK_2_CELL_1', 'STACK_2_CELL_2', 'STACK_2_CELL_3', 'STACK_2_CELL_4',\n",
    "    'STACK_3_CELL_1', 'STACK_3_CELL_2', 'STACK_3_CELL_3', 'STACK_3_CELL_4',\n",
    "    'STACK_4_CELL_1', 'STACK_4_CELL_2', 'STACK_4_CELL_3', 'STACK_4_CELL_4',\n",
    "    'STACK_5_CELL_1', 'STACK_5_CELL_2', 'STACK_5_CELL_3', 'STACK_5_CELL_4',\n",
    "    'STACK_6_CELL_1', 'STACK_6_CELL_2', 'STACK_6_CELL_3', 'STACK_6_CELL_4',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11605950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76_DRIVER_INPUTS.csv...\n",
      "77_ECU_MODE.csv...\n",
      "78_TORQUE_REFERENCE.csv...\n",
      "79_WHEEL_SPEED.csv...\n",
      "80_MOTOR_SPEED.csv...\n",
      "85_LEFT_MOTOR_TRACTIVE.csv...\n",
      "95_RIGHT_MOTOR_TRACTIVE.csv...\n",
      "259_ACCELEROMETER.csv...\n",
      "260_GYROSCOPE.csv...\n",
      "261_ELETROBUILD_TEMPERATURE.csv...\n",
      "300_STACK_1_VOLTAGE.csv...\n",
      "301_STACK_2_VOLTAGE.csv...\n",
      "302_STACK_3_VOLTAGE.csv...\n",
      "303_STACK_4_VOLTAGE.csv...\n",
      "304_STACK_5_VOLTAGE.csv...\n",
      "305_STACK_6_VOLTAGE.csv...\n",
      "306_ACCUMULADOR_PARAMS.csv...\n",
      "307_BMS_PARAMS.csv...\n"
     ]
    }
   ],
   "source": [
    "full_folder = \"./data/dados_telemetria/teste_odonto_08122025/full\"\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name + \"...\")\n",
    "    dfs_list = []\n",
    "    for folder in folder_names:\n",
    "        dfs_list.append(pd.read_csv(f\"{folder}/{file_name}\"))\n",
    "\n",
    "    combined_df = pd.concat(dfs_list, ignore_index=True)\n",
    "    combined_df.to_csv(f\"{full_folder}/{\"FULL_\" + file_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3127c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311_STACK_OVER_ERROR.csv...\n",
      "312_STACK_ERROR_UNDER.csv...\n"
     ]
    }
   ],
   "source": [
    "# agora junta as que nao estao no inicial\n",
    "extra_file_names = [\n",
    "    \"311_STACK_OVER_ERROR.csv\",\n",
    "    \"312_STACK_ERROR_UNDER.csv\",\n",
    "]\n",
    "\n",
    "extra_folder_names = [\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste5_0812\",\n",
    "    \"./data/dados_telemetria/teste_odonto_08122025/teste7_longer\",\n",
    "]\n",
    "\n",
    "full_folder = \"./data/dados_telemetria/teste_odonto_08122025/full\"\n",
    "\n",
    "for file_name in extra_file_names:\n",
    "    print(file_name + \"...\")\n",
    "    dfs_list = []\n",
    "    for folder in extra_folder_names:\n",
    "        dfs_list.append(pd.read_csv(f\"{folder}/{file_name}\"))\n",
    "\n",
    "    combined_df = pd.concat(dfs_list, ignore_index=True)\n",
    "    combined_df.to_csv(f\"{full_folder}/{\"FULL_\" + file_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3af037fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quais colunas precisa refatorar para colocar no arquivo final FULL.csv\n",
    "# (old_name, new_name)\n",
    "columns_rename_map = {\n",
    "    \"FULL_77_ECU_MODE.csv\": [(\"MODE_ID\", \"ECU_MODE_ID\"), (\"TORQUE_GAIN_ID\", \"TORQUE_GAIN\")],\n",
    "    \"FULL_85_LEFT_MOTOR_TRACTIVE.csv\": [(\"SPEED\", \"LEFT_MOTOR_SPEED\")],\n",
    "    \"FULL_95_RIGHT_MOTOR_TRACTIVE.csv\": [(\"SPEED\", \"RIGHT_MOTOR_SPEED\")],\n",
    "    \"FULL_259_ACCELEROMETER.csv\": [(\"ACCEL_Z\", \"ACCEL_LONGITUDINAL\")],\n",
    "    \"FULL_300_STACK_1_VOLTAGE.csv\": [\n",
    "        (\"CEL_1\", \"STACK_1_CELL_1\"), (\"CEL_2\", \"STACK_1_CELL_2\"), (\"CEL_3\", \"STACK_1_CELL_3\"), (\"CEL_4\", \"STACK_1_CELL_4\")\n",
    "    ],\n",
    "    \"FULL_301_STACK_2_VOLTAGE.csv\": [\n",
    "        (\"CEL_1\", \"STACK_2_CELL_1\"), (\"CEL_2\", \"STACK_2_CELL_2\"), (\"CEL_3\", \"STACK_2_CELL_3\"), (\"CEL_4\", \"STACK_2_CELL_4\")\n",
    "    ],\n",
    "    \"FULL_302_STACK_3_VOLTAGE.csv\": [\n",
    "        (\"CEL_1\", \"STACK_3_CELL_1\"), (\"CEL_2\", \"STACK_3_CELL_2\"), (\"CEL_3\", \"STACK_3_CELL_3\"), (\"CEL_4\", \"STACK_3_CELL_4\")\n",
    "    ],\n",
    "    \"FULL_303_STACK_4_VOLTAGE.csv\": [\n",
    "        (\"CEL_1\", \"STACK_4_CELL_1\"), (\"CEL_2\", \"STACK_4_CELL_2\"), (\"CEL_3\", \"STACK_4_CELL_3\"), (\"CEL_4\", \"STACK_4_CELL_4\")\n",
    "    ],\n",
    "    \"FULL_304_STACK_5_VOLTAGE.csv\": [\n",
    "        (\"CEL_1\", \"STACK_5_CELL_1\"), (\"CEL_2\", \"STACK_5_CELL_2\"), (\"CEL_3\", \"STACK_5_CELL_3\"), (\"CEL_4\", \"STACK_5_CELL_4\")\n",
    "    ],\n",
    "    \"FULL_305_STACK_6_VOLTAGE.csv\": [\n",
    "        (\"CEL_1\", \"STACK_6_CELL_1\"), (\"CEL_2\", \"STACK_6_CELL_2\"), (\"CEL_3\", \"STACK_6_CELL_3\"), (\"CEL_4\", \"STACK_6_CELL_4\")\n",
    "    ],\n",
    "    \"FULL_306_ACCUMULADOR_PARAMS.csv\": [(\"SHUNT_VOLTAGE\", \"SHUNT_CURRENT\")],\n",
    "    \"FULL_307_BMS_PARAMS.csv\": [(\"MODE_ID\", \"BMS_MODE_ID\"), (\"ERROR_ID\", \"BMS_ERROR_ID\")],\n",
    "}\n",
    "\n",
    "# quais colunas vou efetivamente usar dos full individuais - nomes refatorados ja\n",
    "file_columns_map = {\n",
    "    'FULL_76_DRIVER_INPUTS.csv': ['THROTTLE', 'BRAKE'],\n",
    "    'FULL_77_ECU_MODE.csv': ['ECU_MODE_ID', 'TORQUE_GAIN'],\n",
    "    'FULL_78_TORQUE_REFERENCE.csv': ['TORQUE_REF_LEFT_MOTOR', 'TORQUE_REF_RIGHT_MOTOR'],\n",
    "    'FULL_85_LEFT_MOTOR_TRACTIVE.csv': ['LEFT_MOTOR_SPEED'],\n",
    "    'FULL_95_RIGHT_MOTOR_TRACTIVE.csv': ['RIGHT_MOTOR_SPEED'],\n",
    "    'FULL_259_ACCELEROMETER.csv': ['ACCEL_LONGITUDINAL'],\n",
    "    'FULL_300_STACK_1_VOLTAGE.csv': ['STACK_1_CELL_1', 'STACK_1_CELL_2', 'STACK_1_CELL_3', 'STACK_1_CELL_4'],\n",
    "    'FULL_301_STACK_2_VOLTAGE.csv': ['STACK_2_CELL_1', 'STACK_2_CELL_2', 'STACK_2_CELL_3', 'STACK_2_CELL_4'],\n",
    "    'FULL_302_STACK_3_VOLTAGE.csv': ['STACK_3_CELL_1', 'STACK_3_CELL_2', 'STACK_3_CELL_3', 'STACK_3_CELL_4'],\n",
    "    'FULL_303_STACK_4_VOLTAGE.csv': ['STACK_4_CELL_1', 'STACK_4_CELL_2', 'STACK_4_CELL_3', 'STACK_4_CELL_4'],\n",
    "    'FULL_304_STACK_5_VOLTAGE.csv': ['STACK_5_CELL_1', 'STACK_5_CELL_2', 'STACK_5_CELL_3', 'STACK_5_CELL_4'],\n",
    "    'FULL_305_STACK_6_VOLTAGE.csv': ['STACK_6_CELL_1', 'STACK_6_CELL_2', 'STACK_6_CELL_3', 'STACK_6_CELL_4'],\n",
    "    'FULL_306_ACCUMULADOR_PARAMS.csv': ['MAX_VOLTAGE', 'MIN_VOLTAGE', 'TOTAL_VOLTAGE', 'SHUNT_CURRENT'],\n",
    "    'FULL_307_BMS_PARAMS.csv': ['BMS_MODE_ID', 'BMS_ERROR_ID', 'AIR_P', 'AIR_N'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9959b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL_76_DRIVER_INPUTS.csv...\n",
      "FULL_77_ECU_MODE.csv...\n",
      "FULL_78_TORQUE_REFERENCE.csv...\n",
      "FULL_79_WHEEL_SPEED.csv...\n",
      "FULL_80_MOTOR_SPEED.csv...\n",
      "FULL_85_LEFT_MOTOR_TRACTIVE.csv...\n",
      "FULL_95_RIGHT_MOTOR_TRACTIVE.csv...\n",
      "FULL_259_ACCELEROMETER.csv...\n",
      "FULL_260_GYROSCOPE.csv...\n",
      "FULL_261_ELETROBUILD_TEMPERATURE.csv...\n",
      "FULL_300_STACK_1_VOLTAGE.csv...\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_8212\\3975095963.py:77: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_df = pd.concat([full_df, new_rows], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL_301_STACK_2_VOLTAGE.csv...\n",
      "FULL_302_STACK_3_VOLTAGE.csv...\n",
      "FULL_303_STACK_4_VOLTAGE.csv...\n",
      "FULL_304_STACK_5_VOLTAGE.csv...\n",
      "FULL_305_STACK_6_VOLTAGE.csv...\n",
      "FULL_306_ACCUMULADOR_PARAMS.csv...\n",
      "FULL_307_BMS_PARAMS.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_8212\\3975095963.py:91: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filled_df = grouped_df.fillna(method='ffill')\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_8212\\3975095963.py:91: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  filled_df = grouped_df.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# passa pelos fulls: remove timestamps que estão fora dos ranges\n",
    "def is_in_range(timestamp):\n",
    "    for key in interest_timestamps:\n",
    "        start_date, end_date = interest_timestamps[key]\n",
    "\n",
    "        start_timestamp = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "        end_timestamp = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "\n",
    "        if timestamp >= start_timestamp and timestamp <= end_timestamp:\n",
    "            return True, key\n",
    "        \n",
    "    return False, None\n",
    "\n",
    "full_folder = \"./data/dados_telemetria/teste_odonto_08122025/full\"\n",
    "# full_file_names = file_names + extra_file_names\n",
    "full_file_names = file_names\n",
    "\n",
    "for i in range(len(full_file_names)):\n",
    "    full_file_names[i] = \"FULL_\" + full_file_names[i]\n",
    "\n",
    "for file_name in full_file_names:\n",
    "    print(file_name + \"...\")\n",
    "\n",
    "    if file_name == 'FULL_300_STACK_1_VOLTAGE.csv':\n",
    "        print(\"here\")\n",
    "\n",
    "    # verifica se existe na lista do file_columns_map\n",
    "    if file_name not in file_columns_map:\n",
    "        continue\n",
    "\n",
    "    # le o arquivo atual\n",
    "    df = pd.read_csv(f'{full_folder}/{file_name}')\n",
    "\n",
    "    # monta o dicionario de dados desse arquivo\n",
    "    data_row = {}\n",
    "\n",
    "    for column in columns:\n",
    "        data_row[column] = []\n",
    "\n",
    "    # varre os timestamps\n",
    "    for i in range (df.shape[0]):\n",
    "        curr_timestamp = df.iloc[i, 1] \n",
    "        is_range, key = is_in_range(timestamp=curr_timestamp)\n",
    "        \n",
    "        if is_range:\n",
    "            # pega as colunas desse arquivo\n",
    "            columns_to_add = file_columns_map[file_name]\n",
    "\n",
    "            # para cada coluna do full_df\n",
    "            for col in full_df.columns:\n",
    "                if col == 'timestamp': \n",
    "                    data_row['timestamp'].append(curr_timestamp)\n",
    "                    continue \n",
    "\n",
    "                # verifica se essa coluna tem dados para adicionar\n",
    "                if col in columns_to_add:\n",
    "                    # se o arquivo atual esta na lista de refatoração\n",
    "                    if file_name in columns_rename_map:\n",
    "                        refactor_list = columns_rename_map[file_name]\n",
    "                        result = next((item for item in refactor_list if item[1] == col), None)\n",
    "\n",
    "                        if result == None:\n",
    "                            # a coluna atual nao precisa de refatoração\n",
    "                            data_row[col].append(df.iloc[i][col])\n",
    "                            continue\n",
    "                        \n",
    "                        old_name, new_name = result\n",
    "                        data_row[new_name].append(df.iloc[i][old_name])\n",
    "                    else:\n",
    "                        data_row[col].append(df.iloc[i][col])\n",
    "                else:\n",
    "                    # sem dados para adicionar\n",
    "                    data_row[col].append(np.nan)\n",
    "\n",
    "    # salva o dicionario na full_df\n",
    "    new_rows = pd.DataFrame(data_row)\n",
    "    full_df = pd.concat([full_df, new_rows], ignore_index=True)\n",
    "\n",
    "# ordena o df por timestamp\n",
    "sorted_df = full_df.sort_values(by='timestamp')\n",
    "\n",
    "# agrupa e toma a media de timestamps duplicados\n",
    "grouped_df = sorted_df.groupby('timestamp', as_index=False).mean()\n",
    "\n",
    "# zera as medições NA da primeira linha\n",
    "for j in range(grouped_df.shape[1]):\n",
    "    if pd.isna(grouped_df.iloc[0, j]):\n",
    "        grouped_df.iloc[0, j] = 0\n",
    "\n",
    "# remover os NA puxando o valor do timestamp anterior\n",
    "filled_df = grouped_df.fillna(method='ffill')\n",
    "\n",
    "TRANSMISSION_RATIO = 8.89\n",
    "WHEEL_RADIUS = 20.5 * 2.54 / 2 / 100\n",
    "PI = 3.1415\n",
    "MS_TO_KPH = 3.6\n",
    "SHUNT_OFFSET = 45\n",
    "ACCEL_SENSITIVITY_FACTOR = 0.122 / 1000\n",
    "\n",
    "# formata grandezas fisica\n",
    "filled_df['t'] = filled_df['timestamp'] - filled_df['timestamp'][0]\n",
    "filled_df['LEFT_MOTOR_SPEED'] = filled_df['LEFT_MOTOR_SPEED'] / TRANSMISSION_RATIO * WHEEL_RADIUS * 2 * PI / 60 * MS_TO_KPH\n",
    "filled_df['RIGHT_MOTOR_SPEED'] = filled_df['RIGHT_MOTOR_SPEED'] / TRANSMISSION_RATIO * WHEEL_RADIUS * 2 * PI / 60 * MS_TO_KPH\n",
    "filled_df['ACCEL_LONGITUDINAL'] = filled_df['ACCEL_LONGITUDINAL'] * ACCEL_SENSITIVITY_FACTOR\n",
    "filled_df['SHUNT_CURRENT'] = filled_df['SHUNT_CURRENT'] - SHUNT_OFFSET\n",
    "\n",
    "# remove dados de ruidos / absurdos\n",
    "for i in range(1, filled_df.shape[0]):\n",
    "    if filled_df.loc[i, 'THROTTLE'] > 1500 or filled_df.loc[i, 'THROTTLE'] < 0:\n",
    "        filled_df.loc[i, 'THROTTLE'] = filled_df.loc[i-1, 'THROTTLE']\n",
    "\n",
    "    if filled_df.loc[i, 'BRAKE'] > 100 or filled_df.loc[i, 'BRAKE'] < 0:\n",
    "        filled_df.loc[i, 'BRAKE'] = filled_df.loc[i-1, 'BRAKE']\n",
    "\n",
    "    if filled_df.loc[i, 'ECU_MODE_ID'] > 10 or filled_df.loc[i, 'ECU_MODE_ID'] < 0:\n",
    "        filled_df.loc[i, 'ECU_MODE_ID'] = filled_df.loc[i-1, 'ECU_MODE_ID']\n",
    "\n",
    "    if filled_df.loc[i, 'TORQUE_GAIN'] > 1000 or filled_df.loc[i, 'TORQUE_GAIN'] < 0:\n",
    "        filled_df.loc[i, 'TORQUE_GAIN'] = filled_df.loc[i-1, 'TORQUE_GAIN']\n",
    "\n",
    "    if filled_df.loc[i, 'TORQUE_REF_LEFT_MOTOR'] > 5000 or filled_df.loc[i, 'TORQUE_REF_LEFT_MOTOR'] < 0:\n",
    "        filled_df.loc[i, 'TORQUE_REF_LEFT_MOTOR'] = filled_df.loc[i-1, 'TORQUE_REF_LEFT_MOTOR']\n",
    "\n",
    "    if filled_df.loc[i, 'TORQUE_REF_RIGHT_MOTOR'] > 5000 or filled_df.loc[i, 'TORQUE_REF_RIGHT_MOTOR'] < 0:\n",
    "        filled_df.loc[i, 'TORQUE_REF_RIGHT_MOTOR'] = filled_df.loc[i-1, 'TORQUE_REF_RIGHT_MOTOR']\n",
    "\n",
    "    if filled_df.loc[i, 'LEFT_MOTOR_SPEED'] > 100 or filled_df.loc[i, 'LEFT_MOTOR_SPEED'] < 0:\n",
    "        filled_df.loc[i, 'LEFT_MOTOR_SPEED'] = filled_df.loc[i-1, 'LEFT_MOTOR_SPEED']\n",
    "\n",
    "    if filled_df.loc[i, 'RIGHT_MOTOR_SPEED'] > 100 or filled_df.loc[i, 'RIGHT_MOTOR_SPEED'] < 0:\n",
    "        filled_df.loc[i, 'RIGHT_MOTOR_SPEED'] = filled_df.loc[i-1, 'RIGHT_MOTOR_SPEED']\n",
    "\n",
    "    if filled_df.loc[i, 'ACCEL_LONGITUDINAL'] > 10 or filled_df.loc[i, 'ACCEL_LONGITUDINAL'] < -10:\n",
    "        filled_df.loc[i, 'ACCEL_LONGITUDINAL'] = filled_df.loc[i-1, 'ACCEL_LONGITUDINAL']\n",
    "\n",
    "    for stack in stacks_list:\n",
    "        if filled_df.loc[i, stack] > 10 or filled_df.loc[i, stack] < -10:\n",
    "            filled_df.loc[i, stack] = filled_df.loc[i-1, stack]\n",
    "\n",
    "    if filled_df.loc[i, 'MAX_VOLTAGE'] > 10 or filled_df.loc[i, 'MAX_VOLTAGE'] < -10:\n",
    "        filled_df.loc[i, 'MAX_VOLTAGE'] = filled_df.loc[i-1, 'MAX_VOLTAGE']\n",
    "\n",
    "    if filled_df.loc[i, 'MIN_VOLTAGE'] > 10 or filled_df.loc[i, 'MIN_VOLTAGE'] < -10:\n",
    "        filled_df.loc[i, 'MIN_VOLTAGE'] = filled_df.loc[i-1, 'MIN_VOLTAGE']\n",
    "\n",
    "    if filled_df.loc[i, 'TOTAL_VOLTAGE'] > 200 or filled_df.loc[i, 'TOTAL_VOLTAGE'] < -200:\n",
    "        filled_df.loc[i, 'TOTAL_VOLTAGE'] = filled_df.loc[i-1, 'TOTAL_VOLTAGE']\n",
    "\n",
    "    if filled_df.loc[i, 'SHUNT_CURRENT'] > 800 or filled_df.loc[i, 'SHUNT_CURRENT'] < -800:\n",
    "        filled_df.loc[i, 'SHUNT_CURRENT'] = filled_df.loc[i-1, 'SHUNT_CURRENT']\n",
    "\n",
    "    if filled_df.loc[i, 'BMS_MODE_ID'] > 50 or filled_df.loc[i, 'BMS_MODE_ID'] < 0:\n",
    "        filled_df.loc[i, 'BMS_MODE_ID'] = filled_df.loc[i-1, 'BMS_MODE_ID']\n",
    "\n",
    "    if filled_df.loc[i, 'BMS_ERROR_ID'] > 50 or filled_df.loc[i, 'BMS_ERROR_ID'] < 0:\n",
    "        filled_df.loc[i, 'BMS_ERROR_ID'] = filled_df.loc[i-1, 'BMS_ERROR_ID']\n",
    "\n",
    "    if filled_df.loc[i, 'AIR_P'] > 10 or filled_df.loc[i, 'AIR_P'] < 0:\n",
    "        filled_df.loc[i, 'AIR_P'] = filled_df.loc[i-1, 'AIR_P']\n",
    "\n",
    "    if filled_df.loc[i, 'AIR_N'] > 10 or filled_df.loc[i, 'AIR_N'] < 0:\n",
    "        filled_df.loc[i, 'AIR_N'] = filled_df.loc[i-1, 'AIR_N']\n",
    "\n",
    "# faz o split e salva em cada CSV\n",
    "for key in interest_timestamps:\n",
    "    folder = \"\"\n",
    "\n",
    "    if \"miguelito\" in key: folder = \"miguelito\"\n",
    "    if \"mike\" in key: folder = \"mike\"\n",
    "    if \"pedro\" in key: folder = \"pedro\"\n",
    "\n",
    "    start_date, end_date = interest_timestamps[key]\n",
    "\n",
    "    start_timestamp = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "    end_timestamp = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "\n",
    "    splitted_df = filled_df[(filled_df[\"timestamp\"] >= start_timestamp) & (filled_df[\"timestamp\"] < end_timestamp)]\n",
    "\n",
    "    splitted_df.to_csv(f'{full_folder}/odonto_08122025/{folder}/{key}.csv', index=False)\n",
    "\n",
    "\n",
    "# salva o df final para um CSV novo\n",
    "filled_df.to_csv(f'{full_folder}/full_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
